{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wget in c:\\users\\anton\\anaconda3\\lib\\site-packages (3.2)\n"
     ]
    }
   ],
   "source": [
    "if os.name=='nt':\n",
    "    !pip install wget\n",
    "    import wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUSTOM_MODEL_NAME = 'my_ssd_mobnet' \n",
    "PRETRAINED_MODEL_NAME = 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8'\n",
    "PRETRAINED_MODEL_URL = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz'\n",
    "TF_RECORD_SCRIPT_NAME = 'generate_tfrecord.py'\n",
    "LABEL_MAP_NAME = 'label_map.pbtxt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = {\n",
    "    'WORKSPACE_PATH': os.path.join('Tensorflow', 'workspace'),\n",
    "    'SCRIPTS_PATH': os.path.join('Tensorflow','scripts'),\n",
    "    'APIMODEL_PATH': os.path.join('Tensorflow','models'),\n",
    "    'ANNOTATION_PATH': os.path.join('Tensorflow', 'workspace','annotations'),\n",
    "    'IMAGE_PATH': os.path.join('Tensorflow', 'workspace','images'),\n",
    "    'MODEL_PATH': os.path.join('Tensorflow', 'workspace','models'),\n",
    "    'PRETRAINED_MODEL_PATH': os.path.join('Tensorflow', 'workspace','pre-trained-models'),\n",
    "    'CHECKPOINT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME), \n",
    "    'OUTPUT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'export'), \n",
    "    'TFJS_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfjsexport'), \n",
    "    'TFLITE_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfliteexport'), \n",
    "    'PROTOC_PATH':os.path.join('Tensorflow','protoc')\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = {\n",
    "    'PIPELINE_CONFIG':os.path.join('Tensorflow', 'workspace','models', CUSTOM_MODEL_NAME, 'pipeline.config'),\n",
    "    'TF_RECORD_SCRIPT': os.path.join(paths['SCRIPTS_PATH'], TF_RECORD_SCRIPT_NAME), \n",
    "    'LABELMAP': os.path.join(paths['ANNOTATION_PATH'], LABEL_MAP_NAME)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in paths.values():\n",
    "    if not os.path.exists(path):\n",
    "        if os.name == 'posix':\n",
    "            !mkdir -p {path}\n",
    "        if os.name == 'nt':\n",
    "            !mkdir {path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection')):\n",
    "    !git clone https://github.com/tensorflow/models {paths['APIMODEL_PATH']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://github.com/protocolbuffers/protobuf/releases/download/v3.15.6/protoc-3.15.6-win64.zip\"\n",
    "wget.download(url)\n",
    "!move protoc-3.15.6-win64.zip {paths['PROTOC_PATH']}\n",
    "!cd {paths['PROTOC_PATH']} && tar -xf protoc-3.15.6-win64.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PATH'] += os.pathsep + os.path.abspath(os.path.join(paths['PROTOC_PATH'], 'bin'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///C:/Users/Anton/Desktop/image%20labeling/Tensorflow/models/research/slim\n",
      "Requirement already satisfied: six in c:\\users\\anton\\anaconda3\\lib\\site-packages (from slim==0.1) (1.15.0)\n",
      "Requirement already satisfied: tf-slim>=1.1 in c:\\users\\anton\\anaconda3\\lib\\site-packages\\tf_slim-1.1.0-py3.8.egg (from slim==0.1) (1.1.0)\n",
      "Requirement already satisfied: absl-py>=0.2.2 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from tf-slim>=1.1->slim==0.1) (0.12.0)\n",
      "Installing collected packages: slim\n",
      "  Running setup.py develop for slim\n",
      "Successfully installed slim\n"
     ]
    }
   ],
   "source": [
    "!cd Tensorflow/models/research/slim && pip install -e . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‘Є®ЇЁа®ў ­® д ©«®ў:         1.\n"
     ]
    }
   ],
   "source": [
    "!cd Tensorflow/models/research && copy object_detection\\\\packages\\\\tf2\\\\setup.py setup.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running build\n",
      "running build_py\n",
      "copying object_detection\\protos\\anchor_generator_pb2.py -> build\\lib\\object_detection\\protos\n",
      "copying object_detection\\protos\\argmax_matcher_pb2.py -> build\\lib\\object_detection\\protos\n",
      "copying object_detection\\protos\\bipartite_matcher_pb2.py -> build\\lib\\object_detection\\protos\n",
      "copying object_detection\\protos\\box_coder_pb2.py -> build\\lib\\object_detection\\protos\n",
      "copying object_detection\\protos\\box_predictor_pb2.py -> build\\lib\\object_detection\\protos\n",
      "copying object_detection\\protos\\calibration_pb2.py -> build\\lib\\object_detection\\protos\n",
      "copying object_detection\\protos\\center_net_pb2.py -> build\\lib\\object_detection\\protos\n",
      "copying object_detection\\protos\\eval_pb2.py -> build\\lib\\object_detection\\protos\n",
      "copying object_detection\\protos\\faster_rcnn_box_coder_pb2.py -> build\\lib\\object_detection\\protos\n",
      "copying object_detection\\protos\\faster_rcnn_pb2.py -> build\\lib\\object_detection\\protos\n",
      "copying object_detection\\protos\\flexible_grid_anchor_generator_pb2.py -> build\\lib\\object_detection\\protos\n",
      "copying object_detection\\protos\\fpn_pb2.py -> build\\lib\\object_detection\\protos\n",
      "copying object_detection\\protos\\graph_rewriter_pb2.py -> build\\lib\\object_detection\\protos\n",
      "copying object_detection\\protos\\grid_anchor_generator_pb2.py -> build\\lib\\object_detection\\protos\n",
      "copying object_detection\\protos\\hyperparams_pb2.py -> build\\lib\\object_detection\\protos\n",
      "copying object_detection\\protos\\image_resizer_pb2.py -> build\\lib\\object_detection\\protos\n",
      "copying object_detection\\protos\\input_reader_pb2.py -> build\\lib\\object_detection\\protos\n",
      "copying object_detection\\protos\\keypoint_box_coder_pb2.py -> build\\lib\\object_detection\\protos\n",
      "copying object_detection\\protos\\losses_pb2.py -> build\\lib\\object_detection\\protos\n",
      "copying object_detection\\protos\\matcher_pb2.py -> build\\lib\\object_detection\\protos\n",
      "copying object_detection\\protos\\mean_stddev_box_coder_pb2.py -> build\\lib\\object_detection\\protos\n",
      "copying object_detection\\protos\\model_pb2.py -> build\\lib\\object_detection\\protos\n",
      "copying object_detection\\protos\\multiscale_anchor_generator_pb2.py -> build\\lib\\object_detection\\protos\n",
      "copying object_detection\\protos\\optimizer_pb2.py -> build\\lib\\object_detection\\protos\n",
      "copying object_detection\\protos\\pipeline_pb2.py -> build\\lib\\object_detection\\protos\n",
      "copying object_detection\\protos\\post_processing_pb2.py -> build\\lib\\object_detection\\protos\n",
      "copying object_detection\\protos\\preprocessor_pb2.py -> build\\lib\\object_detection\\protos\n",
      "copying object_detection\\protos\\region_similarity_calculator_pb2.py -> build\\lib\\object_detection\\protos\n",
      "copying object_detection\\protos\\square_box_coder_pb2.py -> build\\lib\\object_detection\\protos\n",
      "copying object_detection\\protos\\ssd_anchor_generator_pb2.py -> build\\lib\\object_detection\\protos\n",
      "copying object_detection\\protos\\ssd_pb2.py -> build\\lib\\object_detection\\protos\n",
      "copying object_detection\\protos\\string_int_label_map_pb2.py -> build\\lib\\object_detection\\protos\n",
      "copying object_detection\\protos\\target_assigner_pb2.py -> build\\lib\\object_detection\\protos\n",
      "copying object_detection\\protos\\train_pb2.py -> build\\lib\\object_detection\\protos\n",
      "running egg_info\n",
      "writing object_detection.egg-info\\PKG-INFO\n",
      "writing dependency_links to object_detection.egg-info\\dependency_links.txt\n",
      "writing requirements to object_detection.egg-info\\requires.txt\n",
      "writing top-level names to object_detection.egg-info\\top_level.txt\n",
      "reading manifest file 'object_detection.egg-info\\SOURCES.txt'\n",
      "writing manifest file 'object_detection.egg-info\\SOURCES.txt'\n"
     ]
    }
   ],
   "source": [
    "!cd Tensorflow/models/research && python setup.py build "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd Tensorflow/models/research && python setup.py install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-12 13:48:14.842698: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2021-06-12 13:48:14.842743: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "Running tests under Python 3.8.5: C:\\Users\\Anton\\anaconda3\\python.exe\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
      "2021-06-12 13:48:19.330378: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library nvcuda.dll\n",
      "2021-06-12 13:48:19.988263: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: GeForce MX150 computeCapability: 6.1\n",
      "coreClock: 1.341GHz coreCount: 3 deviceMemorySize: 2.00GiB deviceMemoryBandwidth: 37.33GiB/s\n",
      "2021-06-12 13:48:19.988971: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2021-06-12 13:48:19.989590: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cublas64_11.dll'; dlerror: cublas64_11.dll not found\n",
      "2021-06-12 13:48:19.990178: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cublasLt64_11.dll'; dlerror: cublasLt64_11.dll not found\n",
      "2021-06-12 13:48:19.990775: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cufft64_10.dll'; dlerror: cufft64_10.dll not found\n",
      "2021-06-12 13:48:19.991362: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'curand64_10.dll'; dlerror: curand64_10.dll not found\n",
      "2021-06-12 13:48:19.991988: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cusolver64_11.dll'; dlerror: cusolver64_11.dll not found\n",
      "2021-06-12 13:48:19.992582: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cusparse64_11.dll'; dlerror: cusparse64_11.dll not found\n",
      "2021-06-12 13:48:19.993161: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudnn64_8.dll'; dlerror: cudnn64_8.dll not found\n",
      "2021-06-12 13:48:19.993178: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1766] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2021-06-12 13:48:19.993620: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-06-12 13:48:19.994419: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-06-12 13:48:19.994433: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      \n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\object_detection-0.1-py3.8.egg\\object_detection\\builders\\model_builder.py:1085: DeprecationWarning: The 'warn' function is deprecated, use 'warning' instead\n",
      "  logging.warn(('Building experimental DeepMAC meta-arch.'\n",
      "W0612 13:48:20.194279  7008 model_builder.py:1085] Building experimental DeepMAC meta-arch. Some features may be omitted.\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 1.08s\n",
      "I0612 13:48:20.409959  7008 test_util.py:2102] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 1.08s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 1.07s\n",
      "I0612 13:48:21.484848  7008 test_util.py:2102] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 1.07s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.23s\n",
      "I0612 13:48:21.719963  7008 test_util.py:2102] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.23s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.29s\n",
      "I0612 13:48:22.009855  7008 test_util.py:2102] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.29s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "W0612 13:48:22.020050  7008 mobilenet_v2.py:296] `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 2.06s\n",
      "I0612 13:48:24.074407  7008 test_util.py:2102] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 2.06s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
      "I0612 13:48:24.074407  7008 test_util.py:2102] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.02s\n",
      "I0612 13:48:24.093407  7008 test_util.py:2102] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.02s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.01s\n",
      "I0612 13:48:24.107407  7008 test_util.py:2102] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.01s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.01s\n",
      "I0612 13:48:24.120407  7008 test_util.py:2102] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.01s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.09s\n",
      "I0612 13:48:24.206588  7008 test_util.py:2102] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.09s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.08s\n",
      "I0612 13:48:24.288309  7008 test_util.py:2102] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.08s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.09s\n",
      "I0612 13:48:24.374070  7008 test_util.py:2102] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.09s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.09s\n",
      "I0612 13:48:24.460170  7008 test_util.py:2102] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.09s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.08s\n",
      "I0612 13:48:24.544272  7008 test_util.py:2102] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.08s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.02s\n",
      "I0612 13:48:24.567270  7008 test_util.py:2102] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.02s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
      "I0612 13:48:24.716323  7008 ssd_efficientnet_bifpn_feature_extractor.py:142] EfficientDet EfficientNet backbone version: efficientnet-b0\n",
      "I0612 13:48:24.716323  7008 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 64\n",
      "I0612 13:48:24.717323  7008 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num iterations: 3\n",
      "I0612 13:48:24.718283  7008 efficientnet_model.py:147] round_filter input=32 output=32\n",
      "I0612 13:48:24.735321  7008 efficientnet_model.py:147] round_filter input=32 output=32\n",
      "I0612 13:48:24.735321  7008 efficientnet_model.py:147] round_filter input=16 output=16\n",
      "I0612 13:48:24.796322  7008 efficientnet_model.py:147] round_filter input=16 output=16\n",
      "I0612 13:48:24.797322  7008 efficientnet_model.py:147] round_filter input=24 output=24\n",
      "I0612 13:48:24.955373  7008 efficientnet_model.py:147] round_filter input=24 output=24\n",
      "I0612 13:48:24.955373  7008 efficientnet_model.py:147] round_filter input=40 output=40\n",
      "I0612 13:48:25.229421  7008 efficientnet_model.py:147] round_filter input=40 output=40\n",
      "I0612 13:48:25.230418  7008 efficientnet_model.py:147] round_filter input=80 output=80\n",
      "I0612 13:48:25.474357  7008 efficientnet_model.py:147] round_filter input=80 output=80\n",
      "I0612 13:48:25.475363  7008 efficientnet_model.py:147] round_filter input=112 output=112\n",
      "I0612 13:48:25.721361  7008 efficientnet_model.py:147] round_filter input=112 output=112\n",
      "I0612 13:48:25.721361  7008 efficientnet_model.py:147] round_filter input=192 output=192\n",
      "I0612 13:48:26.066042  7008 efficientnet_model.py:147] round_filter input=192 output=192\n",
      "I0612 13:48:26.066042  7008 efficientnet_model.py:147] round_filter input=320 output=320\n",
      "I0612 13:48:26.152043  7008 efficientnet_model.py:147] round_filter input=1280 output=1280\n",
      "I0612 13:48:26.197080  7008 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0612 13:48:26.243080  7008 ssd_efficientnet_bifpn_feature_extractor.py:142] EfficientDet EfficientNet backbone version: efficientnet-b1\n",
      "I0612 13:48:26.243080  7008 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 88\n",
      "I0612 13:48:26.243080  7008 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num iterations: 4\n",
      "I0612 13:48:26.245080  7008 efficientnet_model.py:147] round_filter input=32 output=32\n",
      "I0612 13:48:26.260084  7008 efficientnet_model.py:147] round_filter input=32 output=32\n",
      "I0612 13:48:26.260084  7008 efficientnet_model.py:147] round_filter input=16 output=16\n",
      "I0612 13:48:26.386200  7008 efficientnet_model.py:147] round_filter input=16 output=16\n",
      "I0612 13:48:26.386200  7008 efficientnet_model.py:147] round_filter input=24 output=24\n",
      "I0612 13:48:26.625539  7008 efficientnet_model.py:147] round_filter input=24 output=24\n",
      "I0612 13:48:26.625539  7008 efficientnet_model.py:147] round_filter input=40 output=40\n",
      "I0612 13:48:26.865499  7008 efficientnet_model.py:147] round_filter input=40 output=40\n",
      "I0612 13:48:26.865499  7008 efficientnet_model.py:147] round_filter input=80 output=80\n",
      "I0612 13:48:27.203497  7008 efficientnet_model.py:147] round_filter input=80 output=80\n",
      "I0612 13:48:27.203497  7008 efficientnet_model.py:147] round_filter input=112 output=112\n",
      "I0612 13:48:27.538624  7008 efficientnet_model.py:147] round_filter input=112 output=112\n",
      "I0612 13:48:27.538624  7008 efficientnet_model.py:147] round_filter input=192 output=192\n",
      "I0612 13:48:27.979693  7008 efficientnet_model.py:147] round_filter input=192 output=192\n",
      "I0612 13:48:27.980697  7008 efficientnet_model.py:147] round_filter input=320 output=320\n",
      "I0612 13:48:28.171429  7008 efficientnet_model.py:147] round_filter input=1280 output=1280\n",
      "I0612 13:48:28.210185  7008 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0612 13:48:28.269818  7008 ssd_efficientnet_bifpn_feature_extractor.py:142] EfficientDet EfficientNet backbone version: efficientnet-b2\n",
      "I0612 13:48:28.269818  7008 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 112\n",
      "I0612 13:48:28.269818  7008 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num iterations: 5\n",
      "I0612 13:48:28.269818  7008 efficientnet_model.py:147] round_filter input=32 output=32\n",
      "I0612 13:48:28.288727  7008 efficientnet_model.py:147] round_filter input=32 output=32\n",
      "I0612 13:48:28.288727  7008 efficientnet_model.py:147] round_filter input=16 output=16\n",
      "I0612 13:48:28.411507  7008 efficientnet_model.py:147] round_filter input=16 output=16\n",
      "I0612 13:48:28.411507  7008 efficientnet_model.py:147] round_filter input=24 output=24\n",
      "I0612 13:48:28.655885  7008 efficientnet_model.py:147] round_filter input=24 output=24\n",
      "I0612 13:48:28.656948  7008 efficientnet_model.py:147] round_filter input=40 output=48\n",
      "I0612 13:48:28.899834  7008 efficientnet_model.py:147] round_filter input=40 output=48\n",
      "I0612 13:48:28.899834  7008 efficientnet_model.py:147] round_filter input=80 output=88\n",
      "I0612 13:48:29.365767  7008 efficientnet_model.py:147] round_filter input=80 output=88\n",
      "I0612 13:48:29.366768  7008 efficientnet_model.py:147] round_filter input=112 output=120\n",
      "I0612 13:48:29.708289  7008 efficientnet_model.py:147] round_filter input=112 output=120\n",
      "I0612 13:48:29.708289  7008 efficientnet_model.py:147] round_filter input=192 output=208\n",
      "I0612 13:48:30.150854  7008 efficientnet_model.py:147] round_filter input=192 output=208\n",
      "I0612 13:48:30.150854  7008 efficientnet_model.py:147] round_filter input=320 output=352\n",
      "I0612 13:48:30.342852  7008 efficientnet_model.py:147] round_filter input=1280 output=1408\n",
      "I0612 13:48:30.387852  7008 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0612 13:48:30.443852  7008 ssd_efficientnet_bifpn_feature_extractor.py:142] EfficientDet EfficientNet backbone version: efficientnet-b3\n",
      "I0612 13:48:30.443852  7008 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 160\n",
      "I0612 13:48:30.443852  7008 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num iterations: 6\n",
      "I0612 13:48:30.445852  7008 efficientnet_model.py:147] round_filter input=32 output=40\n",
      "I0612 13:48:30.461852  7008 efficientnet_model.py:147] round_filter input=32 output=40\n",
      "I0612 13:48:30.461852  7008 efficientnet_model.py:147] round_filter input=16 output=24\n",
      "I0612 13:48:30.589363  7008 efficientnet_model.py:147] round_filter input=16 output=24\n",
      "I0612 13:48:30.589363  7008 efficientnet_model.py:147] round_filter input=24 output=32\n",
      "I0612 13:48:30.830361  7008 efficientnet_model.py:147] round_filter input=24 output=32\n",
      "I0612 13:48:30.830361  7008 efficientnet_model.py:147] round_filter input=40 output=48\n",
      "I0612 13:48:31.073362  7008 efficientnet_model.py:147] round_filter input=40 output=48\n",
      "I0612 13:48:31.073362  7008 efficientnet_model.py:147] round_filter input=80 output=96\n",
      "I0612 13:48:31.488363  7008 efficientnet_model.py:147] round_filter input=80 output=96\n",
      "I0612 13:48:31.488363  7008 efficientnet_model.py:147] round_filter input=112 output=136\n",
      "I0612 13:48:31.912363  7008 efficientnet_model.py:147] round_filter input=112 output=136\n",
      "I0612 13:48:31.912363  7008 efficientnet_model.py:147] round_filter input=192 output=232\n",
      "I0612 13:48:32.462404  7008 efficientnet_model.py:147] round_filter input=192 output=232\n",
      "I0612 13:48:32.462404  7008 efficientnet_model.py:147] round_filter input=320 output=384\n",
      "I0612 13:48:32.664805  7008 efficientnet_model.py:147] round_filter input=1280 output=1536\n",
      "I0612 13:48:32.711804  7008 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0612 13:48:32.772648  7008 ssd_efficientnet_bifpn_feature_extractor.py:142] EfficientDet EfficientNet backbone version: efficientnet-b4\n",
      "I0612 13:48:32.772648  7008 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 224\n",
      "I0612 13:48:32.773650  7008 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num iterations: 7\n",
      "I0612 13:48:32.774650  7008 efficientnet_model.py:147] round_filter input=32 output=48\n",
      "I0612 13:48:32.790659  7008 efficientnet_model.py:147] round_filter input=32 output=48\n",
      "I0612 13:48:32.790659  7008 efficientnet_model.py:147] round_filter input=16 output=24\n",
      "I0612 13:48:32.916777  7008 efficientnet_model.py:147] round_filter input=16 output=24\n",
      "I0612 13:48:32.917750  7008 efficientnet_model.py:147] round_filter input=24 output=32\n",
      "I0612 13:48:33.246186  7008 efficientnet_model.py:147] round_filter input=24 output=32\n",
      "I0612 13:48:33.246186  7008 efficientnet_model.py:147] round_filter input=40 output=56\n",
      "I0612 13:48:33.573924  7008 efficientnet_model.py:147] round_filter input=40 output=56\n",
      "I0612 13:48:33.573924  7008 efficientnet_model.py:147] round_filter input=80 output=112\n",
      "I0612 13:48:34.273607  7008 efficientnet_model.py:147] round_filter input=80 output=112\n",
      "I0612 13:48:34.273607  7008 efficientnet_model.py:147] round_filter input=112 output=160\n",
      "I0612 13:48:34.786761  7008 efficientnet_model.py:147] round_filter input=112 output=160\n",
      "I0612 13:48:34.786761  7008 efficientnet_model.py:147] round_filter input=192 output=272\n",
      "I0612 13:48:35.541491  7008 efficientnet_model.py:147] round_filter input=192 output=272\n",
      "I0612 13:48:35.541491  7008 efficientnet_model.py:147] round_filter input=320 output=448\n",
      "I0612 13:48:35.750115  7008 efficientnet_model.py:147] round_filter input=1280 output=1792\n",
      "I0612 13:48:35.799828  7008 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0612 13:48:35.870187  7008 ssd_efficientnet_bifpn_feature_extractor.py:142] EfficientDet EfficientNet backbone version: efficientnet-b5\n",
      "I0612 13:48:35.870187  7008 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 288\n",
      "I0612 13:48:35.870187  7008 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num iterations: 7\n",
      "I0612 13:48:35.877609  7008 efficientnet_model.py:147] round_filter input=32 output=48\n",
      "I0612 13:48:35.889844  7008 efficientnet_model.py:147] round_filter input=32 output=48\n",
      "I0612 13:48:35.889844  7008 efficientnet_model.py:147] round_filter input=16 output=24\n",
      "I0612 13:48:36.090201  7008 efficientnet_model.py:147] round_filter input=16 output=24\n",
      "I0612 13:48:36.090201  7008 efficientnet_model.py:147] round_filter input=24 output=40\n",
      "I0612 13:48:36.513623  7008 efficientnet_model.py:147] round_filter input=24 output=40\n",
      "I0612 13:48:36.514624  7008 efficientnet_model.py:147] round_filter input=40 output=64\n",
      "I0612 13:48:36.925641  7008 efficientnet_model.py:147] round_filter input=40 output=64\n",
      "I0612 13:48:36.925641  7008 efficientnet_model.py:147] round_filter input=80 output=128\n",
      "I0612 13:48:37.526685  7008 efficientnet_model.py:147] round_filter input=80 output=128\n",
      "I0612 13:48:37.527677  7008 efficientnet_model.py:147] round_filter input=112 output=176\n",
      "I0612 13:48:38.150428  7008 efficientnet_model.py:147] round_filter input=112 output=176\n",
      "I0612 13:48:38.150428  7008 efficientnet_model.py:147] round_filter input=192 output=304\n",
      "I0612 13:48:39.224617  7008 efficientnet_model.py:147] round_filter input=192 output=304\n",
      "I0612 13:48:39.224617  7008 efficientnet_model.py:147] round_filter input=320 output=512\n",
      "I0612 13:48:39.579982  7008 efficientnet_model.py:147] round_filter input=1280 output=2048\n",
      "I0612 13:48:39.635984  7008 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0612 13:48:39.728142  7008 ssd_efficientnet_bifpn_feature_extractor.py:142] EfficientDet EfficientNet backbone version: efficientnet-b6\n",
      "I0612 13:48:39.728142  7008 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 384\n",
      "I0612 13:48:39.728142  7008 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num iterations: 8\n",
      "I0612 13:48:39.729992  7008 efficientnet_model.py:147] round_filter input=32 output=56\n",
      "I0612 13:48:39.745992  7008 efficientnet_model.py:147] round_filter input=32 output=56\n",
      "I0612 13:48:39.745992  7008 efficientnet_model.py:147] round_filter input=16 output=32\n",
      "I0612 13:48:39.941034  7008 efficientnet_model.py:147] round_filter input=16 output=32\n",
      "I0612 13:48:39.941034  7008 efficientnet_model.py:147] round_filter input=24 output=40\n",
      "I0612 13:48:40.435290  7008 efficientnet_model.py:147] round_filter input=24 output=40\n",
      "I0612 13:48:40.435290  7008 efficientnet_model.py:147] round_filter input=40 output=72\n",
      "I0612 13:48:40.933017  7008 efficientnet_model.py:147] round_filter input=40 output=72\n",
      "I0612 13:48:40.933017  7008 efficientnet_model.py:147] round_filter input=80 output=144\n",
      "I0612 13:48:41.619869  7008 efficientnet_model.py:147] round_filter input=80 output=144\n",
      "I0612 13:48:41.619869  7008 efficientnet_model.py:147] round_filter input=112 output=200\n",
      "I0612 13:48:42.345813  7008 efficientnet_model.py:147] round_filter input=112 output=200\n",
      "I0612 13:48:42.345813  7008 efficientnet_model.py:147] round_filter input=192 output=344\n",
      "I0612 13:48:43.475842  7008 efficientnet_model.py:147] round_filter input=192 output=344\n",
      "I0612 13:48:43.475842  7008 efficientnet_model.py:147] round_filter input=320 output=576\n",
      "I0612 13:48:43.850841  7008 efficientnet_model.py:147] round_filter input=1280 output=2304\n",
      "I0612 13:48:43.910841  7008 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0612 13:48:44.006841  7008 ssd_efficientnet_bifpn_feature_extractor.py:142] EfficientDet EfficientNet backbone version: efficientnet-b7\n",
      "I0612 13:48:44.006841  7008 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 384\n",
      "I0612 13:48:44.006841  7008 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num iterations: 8\n",
      "I0612 13:48:44.008803  7008 efficientnet_model.py:147] round_filter input=32 output=64\n",
      "I0612 13:48:44.024803  7008 efficientnet_model.py:147] round_filter input=32 output=64\n",
      "I0612 13:48:44.024803  7008 efficientnet_model.py:147] round_filter input=16 output=32\n",
      "I0612 13:48:44.283842  7008 efficientnet_model.py:147] round_filter input=16 output=32\n",
      "I0612 13:48:44.283842  7008 efficientnet_model.py:147] round_filter input=24 output=48\n",
      "I0612 13:48:45.114841  7008 efficientnet_model.py:147] round_filter input=24 output=48\n",
      "I0612 13:48:45.114841  7008 efficientnet_model.py:147] round_filter input=40 output=80\n",
      "I0612 13:48:45.686411  7008 efficientnet_model.py:147] round_filter input=40 output=80\n",
      "I0612 13:48:45.686411  7008 efficientnet_model.py:147] round_filter input=80 output=160\n",
      "I0612 13:48:46.544741  7008 efficientnet_model.py:147] round_filter input=80 output=160\n",
      "I0612 13:48:46.544741  7008 efficientnet_model.py:147] round_filter input=112 output=224\n",
      "I0612 13:48:47.451741  7008 efficientnet_model.py:147] round_filter input=112 output=224\n",
      "I0612 13:48:47.451741  7008 efficientnet_model.py:147] round_filter input=192 output=384\n",
      "I0612 13:48:48.826488  7008 efficientnet_model.py:147] round_filter input=192 output=384\n",
      "I0612 13:48:48.826488  7008 efficientnet_model.py:147] round_filter input=320 output=640\n",
      "I0612 13:48:49.382803  7008 efficientnet_model.py:147] round_filter input=1280 output=2560\n",
      "I0612 13:48:49.444813  7008 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 24.99s\n",
      "I0612 13:48:49.557970  7008 test_util.py:2102] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 24.99s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
      "I0612 13:48:49.562824  7008 test_util.py:2102] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
      "I0612 13:48:49.564806  7008 test_util.py:2102] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
      "I0612 13:48:49.564806  7008 test_util.py:2102] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
      "I0612 13:48:49.566809  7008 test_util.py:2102] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
      "[ RUN      ] ModelBuilderTF2Test.test_session\n",
      "[  SKIPPED ] ModelBuilderTF2Test.test_session\n",
      "[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
      "I0612 13:48:49.568147  7008 test_util.py:2102] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
      "[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
      "I0612 13:48:49.568773  7008 test_util.py:2102] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
      "[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
      "I0612 13:48:49.569807  7008 test_util.py:2102] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
      "----------------------------------------------------------------------\n",
      "Ran 24 tests in 30.245s\n",
      "\n",
      "OK (skipped=1)\n"
     ]
    }
   ],
   "source": [
    "VERIFICATION_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'builders', 'model_builder_tf2_test.py')\n",
    "!python {VERIFICATION_SCRIPT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.5.0-cp38-cp38-win_amd64.whl (422.6 MB)\n",
      "Collecting grpcio~=1.34.0\n",
      "  Downloading grpcio-1.34.1-cp38-cp38-win_amd64.whl (2.9 MB)\n",
      "Requirement already satisfied, skipping upgrade: wheel~=0.35 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from tensorflow) (0.35.1)\n",
      "Requirement already satisfied, skipping upgrade: flatbuffers~=1.12.0 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied, skipping upgrade: google-pasta~=0.2 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied, skipping upgrade: typing-extensions~=3.7.4 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from tensorflow) (3.7.4.3)\n",
      "Collecting tensorboard~=2.5\n",
      "  Downloading tensorboard-2.5.0-py3-none-any.whl (6.0 MB)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.9.2 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from tensorflow) (3.15.7)\n",
      "Requirement already satisfied, skipping upgrade: opt-einsum~=3.3.0 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied, skipping upgrade: astunparse~=1.6.3 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Collecting h5py~=3.1.0\n",
      "  Downloading h5py-3.1.0-cp38-cp38-win_amd64.whl (2.7 MB)\n",
      "Requirement already satisfied, skipping upgrade: termcolor~=1.1.0 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: keras-preprocessing~=1.1.2 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Collecting keras-nightly~=2.5.0.dev\n",
      "  Downloading keras_nightly-2.5.0.dev2021032900-py2.py3-none-any.whl (1.2 MB)\n",
      "Requirement already satisfied, skipping upgrade: six~=1.15.0 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy~=1.19.2 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from tensorflow) (1.19.2)\n",
      "Requirement already satisfied, skipping upgrade: wrapt~=1.12.1 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Collecting gast==0.4.0\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Requirement already satisfied, skipping upgrade: absl-py~=0.10 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from tensorflow) (0.12.0)\n",
      "Collecting tensorflow-estimator<2.6.0,>=2.5.0rc0\n",
      "  Downloading tensorflow_estimator-2.5.0-py2.py3-none-any.whl (462 kB)\n",
      "Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from tensorboard~=2.5->tensorflow) (1.28.0)\n",
      "Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from tensorboard~=2.5->tensorflow) (2.24.0)\n",
      "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from tensorboard~=2.5->tensorflow) (1.0.1)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Requirement already satisfied, skipping upgrade: tensorboard-plugin-wit>=1.6.0 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from tensorboard~=2.5->tensorflow) (1.8.0)\n",
      "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from tensorboard~=2.5->tensorflow) (3.3.4)\n",
      "Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from tensorboard~=2.5->tensorflow) (50.3.1.post20201107)\n",
      "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from tensorboard~=2.5->tensorflow) (0.4.4)\n",
      "Requirement already satisfied, skipping upgrade: rsa<5,>=3.1.4; python_version >= \"3.6\" in c:\\users\\anton\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (4.7.2)\n",
      "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (4.2.1)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (0.2.8)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (2.10)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (2020.6.20)\n",
      "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (1.25.11)\n",
      "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (0.4.8)\n",
      "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow) (3.1.0)\n",
      "Installing collected packages: grpcio, tensorboard-data-server, tensorboard, h5py, keras-nightly, gast, tensorflow-estimator, tensorflow\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.37.0\n",
      "    Uninstalling grpcio-1.37.0:\n",
      "      Successfully uninstalled grpcio-1.37.0\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.4.1\n",
      "    Uninstalling tensorboard-2.4.1:\n",
      "      Successfully uninstalled tensorboard-2.4.1\n",
      "  Attempting uninstall: h5py\n",
      "    Found existing installation: h5py 2.10.0\n",
      "    Uninstalling h5py-2.10.0:\n",
      "      Successfully uninstalled h5py-2.10.0\n",
      "  Attempting uninstall: gast\n",
      "    Found existing installation: gast 0.3.3\n",
      "    Uninstalling gast-0.3.3:\n",
      "      Successfully uninstalled gast-0.3.3\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.4.0\n",
      "    Uninstalling tensorflow-estimator-2.4.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.4.0\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.4.1\n",
      "    Uninstalling tensorflow-2.4.1:\n",
      "      Successfully uninstalled tensorflow-2.4.1\n",
      "Successfully installed gast-0.4.0 grpcio-1.34.1 h5py-3.1.0 keras-nightly-2.5.0.dev2021032900 tensorboard-2.5.0 tensorboard-data-server-0.6.1 tensorflow-2.5.0 tensorflow-estimator-2.5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n",
      "\n",
      "We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n",
      "\n",
      "apache-beam 2.30.0 requires crcmod<2.0,>=1.7, which is not installed.\n",
      "grpcio-tools 1.37.0 requires grpcio>=1.37.0, but you'll have grpcio 1.34.1 which is incompatible.\n",
      "apache-beam 2.30.0 requires avro-python3!=1.9.2,<1.10.0,>=1.8.1, but you'll have avro-python3 1.10.2 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: protobuf 3.15.7\n",
      "Uninstalling protobuf-3.15.7:\n",
      "  Successfully uninstalled protobuf-3.15.7\n",
      "Found existing installation: matplotlib 3.3.2\n",
      "Uninstalling matplotlib-3.3.2:\n",
      "  Successfully uninstalled matplotlib-3.3.2\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow --upgrade\n",
    "!pip uninstall protobuf matplotlib -y\n",
    "!pip install protobuf matplotlib==3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import object_detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% [........................................................................] 20515344 / 20515344ЏҐаҐ¬ҐйҐ­® д ©«®ў:         1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0.data-00000-of-00001\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/checkpoint\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0.index\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/pipeline.config\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/saved_model.pb\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/variables.data-00000-of-00001\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/variables.index\n"
     ]
    }
   ],
   "source": [
    "wget.download(PRETRAINED_MODEL_URL)\n",
    "!move {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
    "!cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [{'name':'counter', 'id':1}]\n",
    "\n",
    "with open(files['LABELMAP'], 'w') as f:\n",
    "    for label in labels:\n",
    "        f.write('item { \\n')\n",
    "        f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n",
    "        f.write('\\tid:{}\\n'.format(label['id']))\n",
    "        f.write('}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'Tensorflow\\scripts' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/nicknochnack/GenerateTFRecord {paths['SCRIPTS_PATH']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created the TFRecord file: Tensorflow\\workspace\\annotations\\train.record\n"
     ]
    }
   ],
   "source": [
    "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'counter')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'train.record')} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created the TFRecord file: Tensorflow\\workspace\\annotations\\test.record\n"
     ]
    }
   ],
   "source": [
    "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'test')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'test.record')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‘Є®ЇЁа®ў ­® д ©«®ў:         1.\n"
     ]
    }
   ],
   "source": [
    "!copy {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.protos import pipeline_pb2\n",
    "from google.protobuf import text_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])\n",
    "pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"r\") as f:                                                                                                                                                                                                                     \n",
    "    proto_str = f.read()                                                                                                                                                                                                                                          \n",
    "    text_format.Merge(proto_str, pipeline_config)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_config.model.ssd.num_classes = len(labels)\n",
    "pipeline_config.train_config.batch_size = 1\n",
    "pipeline_config.train_config.fine_tune_checkpoint = os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'checkpoint', 'ckpt-0')\n",
    "pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n",
    "pipeline_config.train_input_reader.label_map_path= files['LABELMAP']\n",
    "pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'train.record')]\n",
    "pipeline_config.eval_input_reader[0].label_map_path = files['LABELMAP']\n",
    "pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'test.record')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_text = text_format.MessageToString(pipeline_config)                                                                                                                                                                                                        \n",
    "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"wb\") as f:                                                                                                                                                                                                                     \n",
    "    f.write(config_text)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'model_main_tf2.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-12 16:02:54.192672: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2021-06-12 16:02:54.192714: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2021-06-12 16:03:00.027493: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library nvcuda.dll\n",
      "2021-06-12 16:03:00.675454: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce MX150 computeCapability: 6.1\n",
      "coreClock: 1.341GHz coreCount: 3 deviceMemorySize: 2.00GiB deviceMemoryBandwidth: 37.33GiB/s\n",
      "2021-06-12 16:03:00.676147: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2021-06-12 16:03:00.676747: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cublas64_11.dll'; dlerror: cublas64_11.dll not found\n",
      "2021-06-12 16:03:00.677336: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cublasLt64_11.dll'; dlerror: cublasLt64_11.dll not found\n",
      "2021-06-12 16:03:00.677923: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cufft64_10.dll'; dlerror: cufft64_10.dll not found\n",
      "2021-06-12 16:03:00.678508: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'curand64_10.dll'; dlerror: curand64_10.dll not found\n",
      "2021-06-12 16:03:00.679089: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cusolver64_11.dll'; dlerror: cusolver64_11.dll not found\n",
      "2021-06-12 16:03:00.679662: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cusparse64_11.dll'; dlerror: cusparse64_11.dll not found\n",
      "2021-06-12 16:03:00.680239: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudnn64_8.dll'; dlerror: cudnn64_8.dll not found\n",
      "2021-06-12 16:03:00.680255: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1766] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2021-06-12 16:03:00.680745: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-06-12 16:03:00.681380: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-06-12 16:03:00.681395: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      \n",
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "W0612 16:03:00.681810 11224 cross_device_ops.py:1387] There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.\n",
      "W0612 16:03:00.681810 11224 mirrored_strategy.py:379] Collective ops is not configured at program startup. Some performance features may not be enabled.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "I0612 16:03:00.686807 11224 mirrored_strategy.py:369] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "INFO:tensorflow:Maybe overwriting train_steps: 5000\n",
      "I0612 16:03:00.697805 11224 config_util.py:552] Maybe overwriting train_steps: 5000\n",
      "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
      "I0612 16:03:00.697805 11224 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
      "WARNING:tensorflow:From C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\object_detection-0.1-py3.8.egg\\object_detection\\model_lib_v2.py:557: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "rename to distribute_datasets_from_function\n",
      "W0612 16:03:00.714826 11224 deprecation.py:330] From C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\object_detection-0.1-py3.8.egg\\object_detection\\model_lib_v2.py:557: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "rename to distribute_datasets_from_function\n",
      "INFO:tensorflow:Reading unweighted datasets: ['Tensorflow\\\\workspace\\\\annotations\\\\train.record']\n",
      "I0612 16:03:00.724827 11224 dataset_builder.py:163] Reading unweighted datasets: ['Tensorflow\\\\workspace\\\\annotations\\\\train.record']\n",
      "INFO:tensorflow:Reading record datasets for input file: ['Tensorflow\\\\workspace\\\\annotations\\\\train.record']\n",
      "I0612 16:03:00.725826 11224 dataset_builder.py:80] Reading record datasets for input file: ['Tensorflow\\\\workspace\\\\annotations\\\\train.record']\n",
      "INFO:tensorflow:Number of filenames to read: 1\n",
      "I0612 16:03:00.725826 11224 dataset_builder.py:81] Number of filenames to read: 1\n",
      "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
      "W0612 16:03:00.725826 11224 dataset_builder.py:87] num_readers has been reduced to 1 to match input file shards.\n",
      "WARNING:tensorflow:From C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\object_detection-0.1-py3.8.egg\\object_detection\\builders\\dataset_builder.py:101: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n",
      "W0612 16:03:00.727828 11224 deprecation.py:330] From C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\object_detection-0.1-py3.8.egg\\object_detection\\builders\\dataset_builder.py:101: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n",
      "WARNING:tensorflow:From C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\object_detection-0.1-py3.8.egg\\object_detection\\builders\\dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "W0612 16:03:00.754862 11224 deprecation.py:330] From C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\object_detection-0.1-py3.8.egg\\object_detection\\builders\\dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "WARNING:tensorflow:From C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "W0612 16:03:09.158682 11224 deprecation.py:330] From C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "WARNING:tensorflow:From C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
      "W0612 16:03:12.439060 11224 deprecation.py:330] From C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
      "WARNING:tensorflow:From C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:464: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W0612 16:03:14.337018 11224 deprecation.py:330] From C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:464: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "2021-06-12 16:03:17.275859: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py:435: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n",
      "WARNING:tensorflow:From C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:602: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "W0612 16:03:39.271724 13848 deprecation.py:528] From C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:602: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "INFO:tensorflow:Step 100 per-step time 0.730s\n",
      "I0612 16:04:51.149594 11224 model_lib_v2.py:698] Step 100 per-step time 0.730s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.1356738,\n",
      " 'Loss/localization_loss': 0.48924944,\n",
      " 'Loss/regularization_loss': 0.15345363,\n",
      " 'Loss/total_loss': 0.7783769,\n",
      " 'learning_rate': 0.001}\n",
      "I0612 16:04:51.149594 11224 model_lib_v2.py:701] {'Loss/classification_loss': 0.1356738,\n",
      " 'Loss/localization_loss': 0.48924944,\n",
      " 'Loss/regularization_loss': 0.15345363,\n",
      " 'Loss/total_loss': 0.7783769,\n",
      " 'learning_rate': 0.001}\n",
      "INFO:tensorflow:Step 200 per-step time 0.368s\n",
      "I0612 16:05:27.947597 11224 model_lib_v2.py:698] Step 200 per-step time 0.368s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.17036924,\n",
      " 'Loss/localization_loss': 0.16256785,\n",
      " 'Loss/regularization_loss': 0.15347232,\n",
      " 'Loss/total_loss': 0.48640943,\n",
      " 'learning_rate': 0.001}\n",
      "I0612 16:05:27.947597 11224 model_lib_v2.py:701] {'Loss/classification_loss': 0.17036924,\n",
      " 'Loss/localization_loss': 0.16256785,\n",
      " 'Loss/regularization_loss': 0.15347232,\n",
      " 'Loss/total_loss': 0.48640943,\n",
      " 'learning_rate': 0.001}\n",
      "INFO:tensorflow:Step 300 per-step time 0.370s\n",
      "I0612 16:06:04.904597 11224 model_lib_v2.py:698] Step 300 per-step time 0.370s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.20055503,\n",
      " 'Loss/localization_loss': 0.1400532,\n",
      " 'Loss/regularization_loss': 0.15347512,\n",
      " 'Loss/total_loss': 0.49408334,\n",
      " 'learning_rate': 0.001}\n",
      "I0612 16:06:04.904597 11224 model_lib_v2.py:701] {'Loss/classification_loss': 0.20055503,\n",
      " 'Loss/localization_loss': 0.1400532,\n",
      " 'Loss/regularization_loss': 0.15347512,\n",
      " 'Loss/total_loss': 0.49408334,\n",
      " 'learning_rate': 0.001}\n",
      "INFO:tensorflow:Step 400 per-step time 0.368s\n",
      "I0612 16:06:41.728604 11224 model_lib_v2.py:698] Step 400 per-step time 0.368s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.39300314,\n",
      " 'Loss/localization_loss': 0.07153735,\n",
      " 'Loss/regularization_loss': 0.15347598,\n",
      " 'Loss/total_loss': 0.6180165,\n",
      " 'learning_rate': 0.001}\n",
      "I0612 16:06:41.728604 11224 model_lib_v2.py:701] {'Loss/classification_loss': 0.39300314,\n",
      " 'Loss/localization_loss': 0.07153735,\n",
      " 'Loss/regularization_loss': 0.15347598,\n",
      " 'Loss/total_loss': 0.6180165,\n",
      " 'learning_rate': 0.001}\n",
      "INFO:tensorflow:Step 500 per-step time 0.376s\n",
      "I0612 16:07:19.344197 11224 model_lib_v2.py:698] Step 500 per-step time 0.376s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.1406544,\n",
      " 'Loss/localization_loss': 0.06904521,\n",
      " 'Loss/regularization_loss': 0.15347771,\n",
      " 'Loss/total_loss': 0.36317733,\n",
      " 'learning_rate': 0.001}\n",
      "I0612 16:07:19.344197 11224 model_lib_v2.py:701] {'Loss/classification_loss': 0.1406544,\n",
      " 'Loss/localization_loss': 0.06904521,\n",
      " 'Loss/regularization_loss': 0.15347771,\n",
      " 'Loss/total_loss': 0.36317733,\n",
      " 'learning_rate': 0.001}\n",
      "INFO:tensorflow:Step 600 per-step time 0.373s\n",
      "I0612 16:07:56.609187 11224 model_lib_v2.py:698] Step 600 per-step time 0.373s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.07180772,\n",
      " 'Loss/localization_loss': 0.057842597,\n",
      " 'Loss/regularization_loss': 0.15347154,\n",
      " 'Loss/total_loss': 0.28312188,\n",
      " 'learning_rate': 0.001}\n",
      "I0612 16:07:56.609187 11224 model_lib_v2.py:701] {'Loss/classification_loss': 0.07180772,\n",
      " 'Loss/localization_loss': 0.057842597,\n",
      " 'Loss/regularization_loss': 0.15347154,\n",
      " 'Loss/total_loss': 0.28312188,\n",
      " 'learning_rate': 0.001}\n",
      "INFO:tensorflow:Step 700 per-step time 0.368s\n",
      "I0612 16:08:33.442184 11224 model_lib_v2.py:698] Step 700 per-step time 0.368s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.119457774,\n",
      " 'Loss/localization_loss': 0.1003984,\n",
      " 'Loss/regularization_loss': 0.15346965,\n",
      " 'Loss/total_loss': 0.37332582,\n",
      " 'learning_rate': 0.001}\n",
      "I0612 16:08:33.442184 11224 model_lib_v2.py:701] {'Loss/classification_loss': 0.119457774,\n",
      " 'Loss/localization_loss': 0.1003984,\n",
      " 'Loss/regularization_loss': 0.15346965,\n",
      " 'Loss/total_loss': 0.37332582,\n",
      " 'learning_rate': 0.001}\n",
      "INFO:tensorflow:Step 800 per-step time 0.368s\n",
      "I0612 16:09:10.285187 11224 model_lib_v2.py:698] Step 800 per-step time 0.368s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.08232461,\n",
      " 'Loss/localization_loss': 0.10679997,\n",
      " 'Loss/regularization_loss': 0.15346359,\n",
      " 'Loss/total_loss': 0.34258816,\n",
      " 'learning_rate': 0.001}\n",
      "I0612 16:09:10.286187 11224 model_lib_v2.py:701] {'Loss/classification_loss': 0.08232461,\n",
      " 'Loss/localization_loss': 0.10679997,\n",
      " 'Loss/regularization_loss': 0.15346359,\n",
      " 'Loss/total_loss': 0.34258816,\n",
      " 'learning_rate': 0.001}\n",
      "INFO:tensorflow:Step 900 per-step time 0.368s\n",
      "I0612 16:09:47.066185 11224 model_lib_v2.py:698] Step 900 per-step time 0.368s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.12828168,\n",
      " 'Loss/localization_loss': 0.111521184,\n",
      " 'Loss/regularization_loss': 0.15345523,\n",
      " 'Loss/total_loss': 0.3932581,\n",
      " 'learning_rate': 0.001}\n",
      "I0612 16:09:47.066185 11224 model_lib_v2.py:701] {'Loss/classification_loss': 0.12828168,\n",
      " 'Loss/localization_loss': 0.111521184,\n",
      " 'Loss/regularization_loss': 0.15345523,\n",
      " 'Loss/total_loss': 0.3932581,\n",
      " 'learning_rate': 0.001}\n",
      "INFO:tensorflow:Step 1000 per-step time 0.368s\n",
      "I0612 16:10:23.858187 11224 model_lib_v2.py:698] Step 1000 per-step time 0.368s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.11649302,\n",
      " 'Loss/localization_loss': 0.045412533,\n",
      " 'Loss/regularization_loss': 0.15344633,\n",
      " 'Loss/total_loss': 0.3153519,\n",
      " 'learning_rate': 0.001}\n",
      "I0612 16:10:23.858187 11224 model_lib_v2.py:701] {'Loss/classification_loss': 0.11649302,\n",
      " 'Loss/localization_loss': 0.045412533,\n",
      " 'Loss/regularization_loss': 0.15344633,\n",
      " 'Loss/total_loss': 0.3153519,\n",
      " 'learning_rate': 0.001}\n",
      "INFO:tensorflow:Step 1100 per-step time 0.375s\n",
      "I0612 16:11:01.352054 11224 model_lib_v2.py:698] Step 1100 per-step time 0.375s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.03130357,\n",
      " 'Loss/localization_loss': 0.08099672,\n",
      " 'Loss/regularization_loss': 0.15343721,\n",
      " 'Loss/total_loss': 0.2657375,\n",
      " 'learning_rate': 0.0009999898}\n",
      "I0612 16:11:01.352054 11224 model_lib_v2.py:701] {'Loss/classification_loss': 0.03130357,\n",
      " 'Loss/localization_loss': 0.08099672,\n",
      " 'Loss/regularization_loss': 0.15343721,\n",
      " 'Loss/total_loss': 0.2657375,\n",
      " 'learning_rate': 0.0009999898}\n",
      "INFO:tensorflow:Step 1200 per-step time 0.368s\n",
      "I0612 16:11:38.191049 11224 model_lib_v2.py:698] Step 1200 per-step time 0.368s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.0531738,\n",
      " 'Loss/localization_loss': 0.07340967,\n",
      " 'Loss/regularization_loss': 0.15343331,\n",
      " 'Loss/total_loss': 0.28001678,\n",
      " 'learning_rate': 0.000999959}\n",
      "I0612 16:11:38.192048 11224 model_lib_v2.py:701] {'Loss/classification_loss': 0.0531738,\n",
      " 'Loss/localization_loss': 0.07340967,\n",
      " 'Loss/regularization_loss': 0.15343331,\n",
      " 'Loss/total_loss': 0.28001678,\n",
      " 'learning_rate': 0.000999959}\n",
      "INFO:tensorflow:Step 1300 per-step time 0.365s\n",
      "I0612 16:12:14.722048 11224 model_lib_v2.py:698] Step 1300 per-step time 0.365s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.30179605,\n",
      " 'Loss/localization_loss': 0.11356253,\n",
      " 'Loss/regularization_loss': 0.15342483,\n",
      " 'Loss/total_loss': 0.5687834,\n",
      " 'learning_rate': 0.0009999075}\n",
      "I0612 16:12:14.723051 11224 model_lib_v2.py:701] {'Loss/classification_loss': 0.30179605,\n",
      " 'Loss/localization_loss': 0.11356253,\n",
      " 'Loss/regularization_loss': 0.15342483,\n",
      " 'Loss/total_loss': 0.5687834,\n",
      " 'learning_rate': 0.0009999075}\n",
      "INFO:tensorflow:Step 1400 per-step time 0.333s\n",
      "I0612 16:12:48.066050 11224 model_lib_v2.py:698] Step 1400 per-step time 0.333s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.03909102,\n",
      " 'Loss/localization_loss': 0.017331926,\n",
      " 'Loss/regularization_loss': 0.15341666,\n",
      " 'Loss/total_loss': 0.20983961,\n",
      " 'learning_rate': 0.0009998357}\n",
      "I0612 16:12:48.066050 11224 model_lib_v2.py:701] {'Loss/classification_loss': 0.03909102,\n",
      " 'Loss/localization_loss': 0.017331926,\n",
      " 'Loss/regularization_loss': 0.15341666,\n",
      " 'Loss/total_loss': 0.20983961,\n",
      " 'learning_rate': 0.0009998357}\n",
      "INFO:tensorflow:Step 1500 per-step time 0.312s\n",
      "I0612 16:13:19.304049 11224 model_lib_v2.py:698] Step 1500 per-step time 0.312s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.57115054,\n",
      " 'Loss/localization_loss': 0.30338526,\n",
      " 'Loss/regularization_loss': 0.15340862,\n",
      " 'Loss/total_loss': 1.0279444,\n",
      " 'learning_rate': 0.0009997431}\n",
      "I0612 16:13:19.305050 11224 model_lib_v2.py:701] {'Loss/classification_loss': 0.57115054,\n",
      " 'Loss/localization_loss': 0.30338526,\n",
      " 'Loss/regularization_loss': 0.15340862,\n",
      " 'Loss/total_loss': 1.0279444,\n",
      " 'learning_rate': 0.0009997431}\n",
      "INFO:tensorflow:Step 1600 per-step time 0.312s\n",
      "I0612 16:13:50.533048 11224 model_lib_v2.py:698] Step 1600 per-step time 0.312s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.10120138,\n",
      " 'Loss/localization_loss': 0.025895119,\n",
      " 'Loss/regularization_loss': 0.15340489,\n",
      " 'Loss/total_loss': 0.2805014,\n",
      " 'learning_rate': 0.0009996302}\n",
      "I0612 16:13:50.533048 11224 model_lib_v2.py:701] {'Loss/classification_loss': 0.10120138,\n",
      " 'Loss/localization_loss': 0.025895119,\n",
      " 'Loss/regularization_loss': 0.15340489,\n",
      " 'Loss/total_loss': 0.2805014,\n",
      " 'learning_rate': 0.0009996302}\n",
      "INFO:tensorflow:Step 1700 per-step time 0.312s\n",
      "I0612 16:14:21.713049 11224 model_lib_v2.py:698] Step 1700 per-step time 0.312s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.12512402,\n",
      " 'Loss/localization_loss': 0.030820329,\n",
      " 'Loss/regularization_loss': 0.15339667,\n",
      " 'Loss/total_loss': 0.30934104,\n",
      " 'learning_rate': 0.0009994966}\n",
      "I0612 16:14:21.713049 11224 model_lib_v2.py:701] {'Loss/classification_loss': 0.12512402,\n",
      " 'Loss/localization_loss': 0.030820329,\n",
      " 'Loss/regularization_loss': 0.15339667,\n",
      " 'Loss/total_loss': 0.30934104,\n",
      " 'learning_rate': 0.0009994966}\n",
      "INFO:tensorflow:Step 1800 per-step time 0.312s\n",
      "I0612 16:14:52.920049 11224 model_lib_v2.py:698] Step 1800 per-step time 0.312s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.07325737,\n",
      " 'Loss/localization_loss': 0.026532123,\n",
      " 'Loss/regularization_loss': 0.15339166,\n",
      " 'Loss/total_loss': 0.25318116,\n",
      " 'learning_rate': 0.0009993425}\n",
      "I0612 16:14:52.921050 11224 model_lib_v2.py:701] {'Loss/classification_loss': 0.07325737,\n",
      " 'Loss/localization_loss': 0.026532123,\n",
      " 'Loss/regularization_loss': 0.15339166,\n",
      " 'Loss/total_loss': 0.25318116,\n",
      " 'learning_rate': 0.0009993425}\n",
      "INFO:tensorflow:Step 1900 per-step time 0.313s\n",
      "I0612 16:15:24.208048 11224 model_lib_v2.py:698] Step 1900 per-step time 0.313s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.05293271,\n",
      " 'Loss/localization_loss': 0.032263,\n",
      " 'Loss/regularization_loss': 0.15338281,\n",
      " 'Loss/total_loss': 0.23857851,\n",
      " 'learning_rate': 0.0009991678}\n",
      "I0612 16:15:24.208048 11224 model_lib_v2.py:701] {'Loss/classification_loss': 0.05293271,\n",
      " 'Loss/localization_loss': 0.032263,\n",
      " 'Loss/regularization_loss': 0.15338281,\n",
      " 'Loss/total_loss': 0.23857851,\n",
      " 'learning_rate': 0.0009991678}\n",
      "INFO:tensorflow:Step 2000 per-step time 0.312s\n",
      "I0612 16:15:55.448049 11224 model_lib_v2.py:698] Step 2000 per-step time 0.312s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.12462581,\n",
      " 'Loss/localization_loss': 0.01142473,\n",
      " 'Loss/regularization_loss': 0.15337345,\n",
      " 'Loss/total_loss': 0.28942397,\n",
      " 'learning_rate': 0.0009989727}\n",
      "I0612 16:15:55.448049 11224 model_lib_v2.py:701] {'Loss/classification_loss': 0.12462581,\n",
      " 'Loss/localization_loss': 0.01142473,\n",
      " 'Loss/regularization_loss': 0.15337345,\n",
      " 'Loss/total_loss': 0.28942397,\n",
      " 'learning_rate': 0.0009989727}\n",
      "INFO:tensorflow:Step 2100 per-step time 0.317s\n",
      "I0612 16:16:27.122269 11224 model_lib_v2.py:698] Step 2100 per-step time 0.317s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.14154117,\n",
      " 'Loss/localization_loss': 0.022276971,\n",
      " 'Loss/regularization_loss': 0.15336512,\n",
      " 'Loss/total_loss': 0.31718326,\n",
      " 'learning_rate': 0.0009987571}\n",
      "I0612 16:16:27.122269 11224 model_lib_v2.py:701] {'Loss/classification_loss': 0.14154117,\n",
      " 'Loss/localization_loss': 0.022276971,\n",
      " 'Loss/regularization_loss': 0.15336512,\n",
      " 'Loss/total_loss': 0.31718326,\n",
      " 'learning_rate': 0.0009987571}\n",
      "INFO:tensorflow:Step 2200 per-step time 0.312s\n",
      "I0612 16:16:58.319270 11224 model_lib_v2.py:698] Step 2200 per-step time 0.312s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.031545315,\n",
      " 'Loss/localization_loss': 0.021059046,\n",
      " 'Loss/regularization_loss': 0.15335764,\n",
      " 'Loss/total_loss': 0.205962,\n",
      " 'learning_rate': 0.000998521}\n",
      "I0612 16:16:58.319270 11224 model_lib_v2.py:701] {'Loss/classification_loss': 0.031545315,\n",
      " 'Loss/localization_loss': 0.021059046,\n",
      " 'Loss/regularization_loss': 0.15335764,\n",
      " 'Loss/total_loss': 0.205962,\n",
      " 'learning_rate': 0.000998521}\n",
      "INFO:tensorflow:Step 2300 per-step time 0.312s\n",
      "I0612 16:17:29.555269 11224 model_lib_v2.py:698] Step 2300 per-step time 0.312s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.12526338,\n",
      " 'Loss/localization_loss': 0.105027676,\n",
      " 'Loss/regularization_loss': 0.15334731,\n",
      " 'Loss/total_loss': 0.38363838,\n",
      " 'learning_rate': 0.0009982643}\n",
      "I0612 16:17:29.555269 11224 model_lib_v2.py:701] {'Loss/classification_loss': 0.12526338,\n",
      " 'Loss/localization_loss': 0.105027676,\n",
      " 'Loss/regularization_loss': 0.15334731,\n",
      " 'Loss/total_loss': 0.38363838,\n",
      " 'learning_rate': 0.0009982643}\n",
      "INFO:tensorflow:Step 2400 per-step time 0.313s\n",
      "I0612 16:18:00.814271 11224 model_lib_v2.py:698] Step 2400 per-step time 0.313s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.021557257,\n",
      " 'Loss/localization_loss': 0.016177626,\n",
      " 'Loss/regularization_loss': 0.15333788,\n",
      " 'Loss/total_loss': 0.19107276,\n",
      " 'learning_rate': 0.0009979872}\n",
      "I0612 16:18:00.814271 11224 model_lib_v2.py:701] {'Loss/classification_loss': 0.021557257,\n",
      " 'Loss/localization_loss': 0.016177626,\n",
      " 'Loss/regularization_loss': 0.15333788,\n",
      " 'Loss/total_loss': 0.19107276,\n",
      " 'learning_rate': 0.0009979872}\n",
      "INFO:tensorflow:Step 2500 per-step time 0.312s\n",
      "I0612 16:18:32.051270 11224 model_lib_v2.py:698] Step 2500 per-step time 0.312s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.05178827,\n",
      " 'Loss/localization_loss': 0.00614295,\n",
      " 'Loss/regularization_loss': 0.15332751,\n",
      " 'Loss/total_loss': 0.21125872,\n",
      " 'learning_rate': 0.0009976896}\n",
      "I0612 16:18:32.051270 11224 model_lib_v2.py:701] {'Loss/classification_loss': 0.05178827,\n",
      " 'Loss/localization_loss': 0.00614295,\n",
      " 'Loss/regularization_loss': 0.15332751,\n",
      " 'Loss/total_loss': 0.21125872,\n",
      " 'learning_rate': 0.0009976896}\n",
      "INFO:tensorflow:Step 2600 per-step time 0.312s\n",
      "I0612 16:19:03.260269 11224 model_lib_v2.py:698] Step 2600 per-step time 0.312s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.07916127,\n",
      " 'Loss/localization_loss': 0.05412472,\n",
      " 'Loss/regularization_loss': 0.15332101,\n",
      " 'Loss/total_loss': 0.286607,\n",
      " 'learning_rate': 0.0009973715}\n",
      "I0612 16:19:03.261270 11224 model_lib_v2.py:701] {'Loss/classification_loss': 0.07916127,\n",
      " 'Loss/localization_loss': 0.05412472,\n",
      " 'Loss/regularization_loss': 0.15332101,\n",
      " 'Loss/total_loss': 0.286607,\n",
      " 'learning_rate': 0.0009973715}\n",
      "INFO:tensorflow:Step 2700 per-step time 0.349s\n",
      "I0612 16:19:38.210331 11224 model_lib_v2.py:698] Step 2700 per-step time 0.349s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.0446737,\n",
      " 'Loss/localization_loss': 0.013562968,\n",
      " 'Loss/regularization_loss': 0.15331186,\n",
      " 'Loss/total_loss': 0.21154852,\n",
      " 'learning_rate': 0.0009970331}\n",
      "I0612 16:19:38.211328 11224 model_lib_v2.py:701] {'Loss/classification_loss': 0.0446737,\n",
      " 'Loss/localization_loss': 0.013562968,\n",
      " 'Loss/regularization_loss': 0.15331186,\n",
      " 'Loss/total_loss': 0.21154852,\n",
      " 'learning_rate': 0.0009970331}\n",
      "INFO:tensorflow:Step 2800 per-step time 0.415s\n",
      "I0612 16:20:19.667737 11224 model_lib_v2.py:698] Step 2800 per-step time 0.415s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.04826663,\n",
      " 'Loss/localization_loss': 0.017610429,\n",
      " 'Loss/regularization_loss': 0.15330236,\n",
      " 'Loss/total_loss': 0.21917942,\n",
      " 'learning_rate': 0.0009966741}\n",
      "I0612 16:20:19.667737 11224 model_lib_v2.py:701] {'Loss/classification_loss': 0.04826663,\n",
      " 'Loss/localization_loss': 0.017610429,\n",
      " 'Loss/regularization_loss': 0.15330236,\n",
      " 'Loss/total_loss': 0.21917942,\n",
      " 'learning_rate': 0.0009966741}\n",
      "INFO:tensorflow:Step 2900 per-step time 0.430s\n",
      "I0612 16:21:02.673902 11224 model_lib_v2.py:698] Step 2900 per-step time 0.430s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.10367662,\n",
      " 'Loss/localization_loss': 0.018895267,\n",
      " 'Loss/regularization_loss': 0.1532936,\n",
      " 'Loss/total_loss': 0.2758655,\n",
      " 'learning_rate': 0.0009962948}\n",
      "I0612 16:21:02.673902 11224 model_lib_v2.py:701] {'Loss/classification_loss': 0.10367662,\n",
      " 'Loss/localization_loss': 0.018895267,\n",
      " 'Loss/regularization_loss': 0.1532936,\n",
      " 'Loss/total_loss': 0.2758655,\n",
      " 'learning_rate': 0.0009962948}\n",
      "INFO:tensorflow:Step 3000 per-step time 0.348s\n",
      "I0612 16:21:37.496936 11224 model_lib_v2.py:698] Step 3000 per-step time 0.348s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.04178023,\n",
      " 'Loss/localization_loss': 0.019057916,\n",
      " 'Loss/regularization_loss': 0.15328416,\n",
      " 'Loss/total_loss': 0.21412231,\n",
      " 'learning_rate': 0.0009958951}\n",
      "I0612 16:21:37.496936 11224 model_lib_v2.py:701] {'Loss/classification_loss': 0.04178023,\n",
      " 'Loss/localization_loss': 0.019057916,\n",
      " 'Loss/regularization_loss': 0.15328416,\n",
      " 'Loss/total_loss': 0.21412231,\n",
      " 'learning_rate': 0.0009958951}\n",
      "INFO:tensorflow:Step 3100 per-step time 0.358s\n",
      "I0612 16:22:13.330520 11224 model_lib_v2.py:698] Step 3100 per-step time 0.358s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.082587324,\n",
      " 'Loss/localization_loss': 0.015767232,\n",
      " 'Loss/regularization_loss': 0.15327676,\n",
      " 'Loss/total_loss': 0.25163132,\n",
      " 'learning_rate': 0.0009954749}\n",
      "I0612 16:22:13.331521 11224 model_lib_v2.py:701] {'Loss/classification_loss': 0.082587324,\n",
      " 'Loss/localization_loss': 0.015767232,\n",
      " 'Loss/regularization_loss': 0.15327676,\n",
      " 'Loss/total_loss': 0.25163132,\n",
      " 'learning_rate': 0.0009954749}\n",
      "INFO:tensorflow:Step 3200 per-step time 0.315s\n",
      "I0612 16:22:44.785523 11224 model_lib_v2.py:698] Step 3200 per-step time 0.315s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.04438617,\n",
      " 'Loss/localization_loss': 0.011174825,\n",
      " 'Loss/regularization_loss': 0.15326744,\n",
      " 'Loss/total_loss': 0.20882845,\n",
      " 'learning_rate': 0.0009950345}\n",
      "I0612 16:22:44.785523 11224 model_lib_v2.py:701] {'Loss/classification_loss': 0.04438617,\n",
      " 'Loss/localization_loss': 0.011174825,\n",
      " 'Loss/regularization_loss': 0.15326744,\n",
      " 'Loss/total_loss': 0.20882845,\n",
      " 'learning_rate': 0.0009950345}\n",
      "INFO:tensorflow:Step 3300 per-step time 0.325s\n",
      "I0612 16:23:17.244520 11224 model_lib_v2.py:698] Step 3300 per-step time 0.325s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.47264314,\n",
      " 'Loss/localization_loss': 0.009651348,\n",
      " 'Loss/regularization_loss': 0.15325804,\n",
      " 'Loss/total_loss': 0.6355525,\n",
      " 'learning_rate': 0.0009945736}\n",
      "I0612 16:23:17.244520 11224 model_lib_v2.py:701] {'Loss/classification_loss': 0.47264314,\n",
      " 'Loss/localization_loss': 0.009651348,\n",
      " 'Loss/regularization_loss': 0.15325804,\n",
      " 'Loss/total_loss': 0.6355525,\n",
      " 'learning_rate': 0.0009945736}\n",
      "INFO:tensorflow:Step 3400 per-step time 0.336s\n",
      "I0612 16:23:50.846521 11224 model_lib_v2.py:698] Step 3400 per-step time 0.336s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.06757494,\n",
      " 'Loss/localization_loss': 0.037502315,\n",
      " 'Loss/regularization_loss': 0.15324774,\n",
      " 'Loss/total_loss': 0.258325,\n",
      " 'learning_rate': 0.0009940924}\n",
      "I0612 16:23:50.847520 11224 model_lib_v2.py:701] {'Loss/classification_loss': 0.06757494,\n",
      " 'Loss/localization_loss': 0.037502315,\n",
      " 'Loss/regularization_loss': 0.15324774,\n",
      " 'Loss/total_loss': 0.258325,\n",
      " 'learning_rate': 0.0009940924}\n",
      "INFO:tensorflow:Step 3500 per-step time 0.364s\n",
      "I0612 16:24:27.280227 11224 model_lib_v2.py:698] Step 3500 per-step time 0.364s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.03256881,\n",
      " 'Loss/localization_loss': 0.0099863205,\n",
      " 'Loss/regularization_loss': 0.15323797,\n",
      " 'Loss/total_loss': 0.1957931,\n",
      " 'learning_rate': 0.0009935909}\n",
      "I0612 16:24:27.280227 11224 model_lib_v2.py:701] {'Loss/classification_loss': 0.03256881,\n",
      " 'Loss/localization_loss': 0.0099863205,\n",
      " 'Loss/regularization_loss': 0.15323797,\n",
      " 'Loss/total_loss': 0.1957931,\n",
      " 'learning_rate': 0.0009935909}\n",
      "INFO:tensorflow:Step 3600 per-step time 0.316s\n",
      "I0612 16:24:58.893225 11224 model_lib_v2.py:698] Step 3600 per-step time 0.316s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.023865972,\n",
      " 'Loss/localization_loss': 0.011387219,\n",
      " 'Loss/regularization_loss': 0.1532287,\n",
      " 'Loss/total_loss': 0.18848188,\n",
      " 'learning_rate': 0.0009930691}\n",
      "I0612 16:24:58.893225 11224 model_lib_v2.py:701] {'Loss/classification_loss': 0.023865972,\n",
      " 'Loss/localization_loss': 0.011387219,\n",
      " 'Loss/regularization_loss': 0.1532287,\n",
      " 'Loss/total_loss': 0.18848188,\n",
      " 'learning_rate': 0.0009930691}\n",
      "INFO:tensorflow:Step 3700 per-step time 0.314s\n",
      "I0612 16:25:30.293227 11224 model_lib_v2.py:698] Step 3700 per-step time 0.314s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.022080388,\n",
      " 'Loss/localization_loss': 0.012593408,\n",
      " 'Loss/regularization_loss': 0.15321906,\n",
      " 'Loss/total_loss': 0.18789285,\n",
      " 'learning_rate': 0.0009925271}\n",
      "I0612 16:25:30.293227 11224 model_lib_v2.py:701] {'Loss/classification_loss': 0.022080388,\n",
      " 'Loss/localization_loss': 0.012593408,\n",
      " 'Loss/regularization_loss': 0.15321906,\n",
      " 'Loss/total_loss': 0.18789285,\n",
      " 'learning_rate': 0.0009925271}\n",
      "INFO:tensorflow:Step 3800 per-step time 0.317s\n",
      "I0612 16:26:01.978750 11224 model_lib_v2.py:698] Step 3800 per-step time 0.317s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.018037338,\n",
      " 'Loss/localization_loss': 0.01896929,\n",
      " 'Loss/regularization_loss': 0.15320934,\n",
      " 'Loss/total_loss': 0.19021598,\n",
      " 'learning_rate': 0.0009919648}\n",
      "I0612 16:26:01.978750 11224 model_lib_v2.py:701] {'Loss/classification_loss': 0.018037338,\n",
      " 'Loss/localization_loss': 0.01896929,\n",
      " 'Loss/regularization_loss': 0.15320934,\n",
      " 'Loss/total_loss': 0.19021598,\n",
      " 'learning_rate': 0.0009919648}\n",
      "INFO:tensorflow:Step 3900 per-step time 0.314s\n",
      "I0612 16:26:33.416749 11224 model_lib_v2.py:698] Step 3900 per-step time 0.314s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.05163095,\n",
      " 'Loss/localization_loss': 0.010233428,\n",
      " 'Loss/regularization_loss': 0.15319994,\n",
      " 'Loss/total_loss': 0.21506432,\n",
      " 'learning_rate': 0.0009913823}\n",
      "I0612 16:26:33.416749 11224 model_lib_v2.py:701] {'Loss/classification_loss': 0.05163095,\n",
      " 'Loss/localization_loss': 0.010233428,\n",
      " 'Loss/regularization_loss': 0.15319994,\n",
      " 'Loss/total_loss': 0.21506432,\n",
      " 'learning_rate': 0.0009913823}\n",
      "INFO:tensorflow:Step 4000 per-step time 0.316s\n",
      "I0612 16:27:04.999750 11224 model_lib_v2.py:698] Step 4000 per-step time 0.316s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.03248608,\n",
      " 'Loss/localization_loss': 0.0063772528,\n",
      " 'Loss/regularization_loss': 0.15318967,\n",
      " 'Loss/total_loss': 0.192053,\n",
      " 'learning_rate': 0.0009907796}\n",
      "I0612 16:27:04.999750 11224 model_lib_v2.py:701] {'Loss/classification_loss': 0.03248608,\n",
      " 'Loss/localization_loss': 0.0063772528,\n",
      " 'Loss/regularization_loss': 0.15318967,\n",
      " 'Loss/total_loss': 0.192053,\n",
      " 'learning_rate': 0.0009907796}\n",
      "INFO:tensorflow:Step 4100 per-step time 0.320s\n",
      "I0612 16:27:36.965857 11224 model_lib_v2.py:698] Step 4100 per-step time 0.320s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.035573952,\n",
      " 'Loss/localization_loss': 0.009656283,\n",
      " 'Loss/regularization_loss': 0.15317865,\n",
      " 'Loss/total_loss': 0.19840887,\n",
      " 'learning_rate': 0.0009901568}\n",
      "I0612 16:27:36.965857 11224 model_lib_v2.py:701] {'Loss/classification_loss': 0.035573952,\n",
      " 'Loss/localization_loss': 0.009656283,\n",
      " 'Loss/regularization_loss': 0.15317865,\n",
      " 'Loss/total_loss': 0.19840887,\n",
      " 'learning_rate': 0.0009901568}\n",
      "INFO:tensorflow:Step 4200 per-step time 0.354s\n",
      "I0612 16:28:12.407812 11224 model_lib_v2.py:698] Step 4200 per-step time 0.354s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.091235094,\n",
      " 'Loss/localization_loss': 0.010398829,\n",
      " 'Loss/regularization_loss': 0.15316822,\n",
      " 'Loss/total_loss': 0.25480214,\n",
      " 'learning_rate': 0.0009895137}\n",
      "I0612 16:28:12.408812 11224 model_lib_v2.py:701] {'Loss/classification_loss': 0.091235094,\n",
      " 'Loss/localization_loss': 0.010398829,\n",
      " 'Loss/regularization_loss': 0.15316822,\n",
      " 'Loss/total_loss': 0.25480214,\n",
      " 'learning_rate': 0.0009895137}\n",
      "INFO:tensorflow:Step 4300 per-step time 0.316s\n",
      "I0612 16:28:44.041976 11224 model_lib_v2.py:698] Step 4300 per-step time 0.316s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.11402409,\n",
      " 'Loss/localization_loss': 0.026796674,\n",
      " 'Loss/regularization_loss': 0.15316221,\n",
      " 'Loss/total_loss': 0.29398295,\n",
      " 'learning_rate': 0.0009888505}\n",
      "I0612 16:28:44.041976 11224 model_lib_v2.py:701] {'Loss/classification_loss': 0.11402409,\n",
      " 'Loss/localization_loss': 0.026796674,\n",
      " 'Loss/regularization_loss': 0.15316221,\n",
      " 'Loss/total_loss': 0.29398295,\n",
      " 'learning_rate': 0.0009888505}\n",
      "INFO:tensorflow:Step 4400 per-step time 0.349s\n",
      "I0612 16:29:18.977975 11224 model_lib_v2.py:698] Step 4400 per-step time 0.349s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.087868035,\n",
      " 'Loss/localization_loss': 0.01350073,\n",
      " 'Loss/regularization_loss': 0.15315273,\n",
      " 'Loss/total_loss': 0.2545215,\n",
      " 'learning_rate': 0.0009881674}\n",
      "I0612 16:29:18.978976 11224 model_lib_v2.py:701] {'Loss/classification_loss': 0.087868035,\n",
      " 'Loss/localization_loss': 0.01350073,\n",
      " 'Loss/regularization_loss': 0.15315273,\n",
      " 'Loss/total_loss': 0.2545215,\n",
      " 'learning_rate': 0.0009881674}\n",
      "INFO:tensorflow:Step 4500 per-step time 0.350s\n",
      "I0612 16:29:53.997980 11224 model_lib_v2.py:698] Step 4500 per-step time 0.350s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.018168628,\n",
      " 'Loss/localization_loss': 0.02026373,\n",
      " 'Loss/regularization_loss': 0.15314306,\n",
      " 'Loss/total_loss': 0.19157542,\n",
      " 'learning_rate': 0.000987464}\n",
      "I0612 16:29:53.998982 11224 model_lib_v2.py:701] {'Loss/classification_loss': 0.018168628,\n",
      " 'Loss/localization_loss': 0.02026373,\n",
      " 'Loss/regularization_loss': 0.15314306,\n",
      " 'Loss/total_loss': 0.19157542,\n",
      " 'learning_rate': 0.000987464}\n",
      "INFO:tensorflow:Step 4600 per-step time 0.362s\n",
      "I0612 16:30:30.218434 11224 model_lib_v2.py:698] Step 4600 per-step time 0.362s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.15037934,\n",
      " 'Loss/localization_loss': 0.026817106,\n",
      " 'Loss/regularization_loss': 0.15313357,\n",
      " 'Loss/total_loss': 0.33033004,\n",
      " 'learning_rate': 0.0009867407}\n",
      "I0612 16:30:30.218434 11224 model_lib_v2.py:701] {'Loss/classification_loss': 0.15037934,\n",
      " 'Loss/localization_loss': 0.026817106,\n",
      " 'Loss/regularization_loss': 0.15313357,\n",
      " 'Loss/total_loss': 0.33033004,\n",
      " 'learning_rate': 0.0009867407}\n",
      "INFO:tensorflow:Step 4700 per-step time 0.351s\n",
      "I0612 16:31:05.295088 11224 model_lib_v2.py:698] Step 4700 per-step time 0.351s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.019850317,\n",
      " 'Loss/localization_loss': 0.0,\n",
      " 'Loss/regularization_loss': 0.15312622,\n",
      " 'Loss/total_loss': 0.17297654,\n",
      " 'learning_rate': 0.0009859973}\n",
      "I0612 16:31:05.295088 11224 model_lib_v2.py:701] {'Loss/classification_loss': 0.019850317,\n",
      " 'Loss/localization_loss': 0.0,\n",
      " 'Loss/regularization_loss': 0.15312622,\n",
      " 'Loss/total_loss': 0.17297654,\n",
      " 'learning_rate': 0.0009859973}\n",
      "INFO:tensorflow:Step 4800 per-step time 0.323s\n",
      "I0612 16:31:37.557927 11224 model_lib_v2.py:698] Step 4800 per-step time 0.323s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.030979965,\n",
      " 'Loss/localization_loss': 0.006474517,\n",
      " 'Loss/regularization_loss': 0.1531161,\n",
      " 'Loss/total_loss': 0.19057058,\n",
      " 'learning_rate': 0.0009852339}\n",
      "I0612 16:31:37.557927 11224 model_lib_v2.py:701] {'Loss/classification_loss': 0.030979965,\n",
      " 'Loss/localization_loss': 0.006474517,\n",
      " 'Loss/regularization_loss': 0.1531161,\n",
      " 'Loss/total_loss': 0.19057058,\n",
      " 'learning_rate': 0.0009852339}\n",
      "INFO:tensorflow:Step 4900 per-step time 0.327s\n",
      "I0612 16:32:10.241709 11224 model_lib_v2.py:698] Step 4900 per-step time 0.327s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.04595318,\n",
      " 'Loss/localization_loss': 0.021398706,\n",
      " 'Loss/regularization_loss': 0.15310997,\n",
      " 'Loss/total_loss': 0.22046186,\n",
      " 'learning_rate': 0.0009844507}\n",
      "I0612 16:32:10.241709 11224 model_lib_v2.py:701] {'Loss/classification_loss': 0.04595318,\n",
      " 'Loss/localization_loss': 0.021398706,\n",
      " 'Loss/regularization_loss': 0.15310997,\n",
      " 'Loss/total_loss': 0.22046186,\n",
      " 'learning_rate': 0.0009844507}\n",
      "INFO:tensorflow:Step 5000 per-step time 0.322s\n",
      "I0612 16:32:42.478223 11224 model_lib_v2.py:698] Step 5000 per-step time 0.322s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.60385513,\n",
      " 'Loss/localization_loss': 0.014515262,\n",
      " 'Loss/regularization_loss': 0.15309967,\n",
      " 'Loss/total_loss': 0.77147007,\n",
      " 'learning_rate': 0.0009836475}\n",
      "I0612 16:32:42.478223 11224 model_lib_v2.py:701] {'Loss/classification_loss': 0.60385513,\n",
      " 'Loss/localization_loss': 0.014515262,\n",
      " 'Loss/regularization_loss': 0.15309967,\n",
      " 'Loss/total_loss': 0.77147007,\n",
      " 'learning_rate': 0.0009836475}\n"
     ]
    }
   ],
   "source": [
    "!python {TRAINING_SCRIPT} --model_dir={paths['CHECKPOINT_PATH']} --pipeline_config_path={files['PIPELINE_CONFIG']} --num_train_steps=5000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python {TRAINING_SCRIPT} --model_dir={paths['CHECKPOINT_PATH']} --pipeline_config_path={files['PIPELINE_CONFIG']} --checkpoint_dir={paths['CHECKPOINT_PATH']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow\\models\\research\\object_detection\\model_main_tf2.py --model_dir=Tensorflow\\workspace\\models\\my_ssd_mobnet --pipeline_config_path=Tensorflow\\workspace\\models\\my_ssd_mobnet\\pipeline.config --checkpoint_dir=Tensorflow\\workspace\\models\\my_ssd_mobnet\n"
     ]
    }
   ],
   "source": [
    "print('{} --model_dir={} --pipeline_config_path={} --checkpoint_dir={}'.format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'], files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tensorboard --logdir={os.path.join(paths['CHECKPOINT_PATH'], 'train')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.join(paths['CHECKPOINT_PATH'], 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.builders import model_builder\n",
    "from object_detection.utils import config_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pipeline config and build a detection model\n",
    "configs = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])\n",
    "detection_model = model_builder.build(model_config=configs['model'], is_training=False)\n",
    "\n",
    "# Restore checkpoint\n",
    "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
    "ckpt.restore(os.path.join(paths['CHECKPOINT_PATH'], 'ckpt-6')).expect_partial()\n",
    "\n",
    "@tf.function\n",
    "def detect_fn(image):\n",
    "    image, shapes = detection_model.preprocess(image)\n",
    "    prediction_dict = detection_model.predict(image, shapes)\n",
    "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
    "    return detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_index = label_map_util.create_category_index_from_labelmap(files['LABELMAP'])\n",
    "IMAGE_PATH = os.path.join(paths['IMAGE_PATH'], 'test_big.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = cv2.imread(IMAGE_PATH)\n",
    "image_np = np.array(img)\n",
    "\n",
    "input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "detections = detect_fn(input_tensor)\n",
    "\n",
    "num_detections = int(detections.pop('num_detections'))\n",
    "detections = {key: value[0, :num_detections].numpy()\n",
    "              for key, value in detections.items()}\n",
    "detections['num_detections'] = num_detections\n",
    "\n",
    "# detection_classes should be ints.\n",
    "detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "label_id_offset = 1\n",
    "image_np_with_detections = image_np.copy()\n",
    "\n",
    "\n",
    "\n",
    "viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "            image_np_with_detections,\n",
    "            detections['detection_boxes'],\n",
    "            detections['detection_classes']+label_id_offset,\n",
    "            detections['detection_scores'],\n",
    "            category_index,\n",
    "            use_normalized_coordinates=True,\n",
    "            max_boxes_to_draw=5,\n",
    "            min_score_thresh=.3,\n",
    "            agnostic_mode=False)\n",
    "\n",
    "plt.imshow(cv2.cvtColor(image_np_with_detections, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[157, 193] [987, 1159]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "width, height = image_np.shape[0], image_np.shape[1]\n",
    "box = detections['detection_boxes'][0].reshape(4, 1)\n",
    "\n",
    "box_y = []\n",
    "box_x = []\n",
    "\n",
    "for i, side in enumerate(box, start=1):\n",
    "    if i % 2 == 0:\n",
    "        side = side*height\n",
    "        box_x.append(math.floor(side[0]))\n",
    "    else:\n",
    "        side = side*width\n",
    "        box_y.append(math.floor(side[0]))\n",
    "\n",
    "print(box_y, box_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[193, [987, 1159]]\n"
     ]
    }
   ],
   "source": [
    "print([box_y[1], box_x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36, 172, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "crop_img = img[box_y[0]:box_y[1], box_x[0]:box_x[1]]\n",
    "print(crop_img.shape)\n",
    "plt.imshow(cv2.cvtColor(crop_img, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "\n",
    "def encode_file(file):\n",
    "    file_content = file.read()\n",
    "    \n",
    "    print('file', file)\n",
    "    \n",
    "    return base64.b64encode(file_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved  counter_2.jpg\n"
     ]
    }
   ],
   "source": [
    "from os import walk\n",
    "from PIL import Image\n",
    "\n",
    "filenames = next(walk('./image2text'), (None, None, []))[2] \n",
    "new_filename = 'counter_'+ str(len(filenames)) + \".jpg\"\n",
    "file_path = \"image2text/\" + new_filename\n",
    "\n",
    "im = Image.fromarray(crop_img)\n",
    "im.save(file_path)\n",
    "\n",
    "print('saved ', new_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import config\n",
    "import json\n",
    "\n",
    "API_ID = config.api_id\n",
    "API_HASH = config.api_hash\n",
    "\n",
    "class APIBody:\n",
    "    folderId = ''\n",
    "    analyze_specs = ''\n",
    "   \n",
    "def image2text_API(content):\n",
    "    body = APIBody()    \n",
    "    body.folderId = \"b1gh8rj6cl05633g58en\"\n",
    "    contentUTF = content.decode('utf-8')  \n",
    "\n",
    "    body.analyze_specs = [{\"content\": contentUTF, \"features\": [{ \"type\": \"TEXT_DETECTION\", \"text_detection_config\": { \"language_codes\": [\"*\"],\"model\": \"line\"}}]}]\n",
    "    jsonBody = json.dumps(body.__dict__)\n",
    "    headers = {'Authorization': 'Bearer ' + config.IAM_TOKEN, \"Content-Type\": \"application/json\"}\n",
    "    \n",
    "    response = requests.post(\"https://vision.api.cloud.yandex.net/vision/v1/batchAnalyze\", data=jsonBody, headers=headers)\n",
    "    print('response', response.content)\n",
    "    \n",
    "    return true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file <_io.BufferedReader name='image2text/counter_2.jpg'>\n",
      "response b'{\\n \"code\": 16,\\n \"message\": \"The token has expired 2021-04-22T20:31:43.530433Z. Now 2021-06-12T15:58:55.017770795Z, which is more than PT10M later\",\\n \"details\": [\\n  {\\n   \"@type\": \"type.googleapis.com/google.rpc.RequestInfo\",\\n   \"requestId\": \"85e66f72-3f6a-40f8-ae31-64e880c862e8\"\\n  }\\n ]\\n}\\n'\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'true' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-265-7f0490a77be8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage2text_API\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencode_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'УРААААА!'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-264-59d0e4a171e0>\u001b[0m in \u001b[0;36mimage2text_API\u001b[1;34m(content)\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'response'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'true' is not defined"
     ]
    }
   ],
   "source": [
    "with open(file_path, \"rb\") as file:\n",
    "    res = image2text_API(encode_file(file))\n",
    "    if res:\n",
    "        print('УРААААА!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
